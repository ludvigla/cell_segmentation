---
title: "cell_segmentation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libs}
library(EBImage)
library(ggplot2)
library(cowplot)
library(magrittr)
library(zeallot)
```

# Define functions
```{r define_functions}
# Define filter function for later
filter_cells <- function(im, brush.size = 9, verbose = FALSE) {
  if (verbose) cat("Applying 2D convolution filter to image ... \n")
  f = makeBrush(brush.size, shape = 'disc', step = FALSE)
  f = f/sum(f)
  imfiltered <- filter2(im, filter = f)
  return(imfiltered)
}


# Define correction function for later
correct_cells <- function(im, imfiltered, verbose = FALSE) {
  if (class(im) != "Image") stop(paste0("Invalid input format of im: ", class(im)))
  if (class(imfiltered) != "Image") stop(paste0("Invalid input format of imfiltered: ", class(imfiltered)))
  if (verbose) cat("Correcting image ... \n")
  imcorrected <- (im - imfiltered) %>% normalize()
  return(imcorrected)
}

# Define threshold function for later
threshold_cells <- function(imcorrected, nsd = 2, verbose = FALSE) {
  if (class(imcorrected) != "Image") stop(paste0("Invalid input format: ", class(imcorrected)))
  if (verbose) cat("Thresholding cells ... \n")
  thr <- mean(imcorrected) + nsd*sd(imcorrected)
  imthreshold <- imcorrected > thr
  return(imthreshold)
}

# Define cleaning function for later
clean_cells <- function(imthreshold, ftr = "s.area", thr = c(5, 40), do.fast = FALSE, verbose = FALSE) {
  if (class(imthreshold) != "Image") stop(paste0("Invalid input format: ", class(imthreshold)))
  if (verbose) cat("Cleaning up unwanted speckles ... \n")
  imthreshold <- bwlabel(imthreshold)
  if (do.fast & ftr == "s.area") {
    areas <- table(imthreshold)[-1]
    inds <- which(areas < thr[1] | areas > thr[2])
  } else if (do.fast & ftr != "s.area") (
    stop(paste0("Invalid option ", ftr, " for ftr. Only ftr = 's.area' can be used for fast shape extraction."))
  ) else {
    fts.shape <- shape_extractor(x = imthreshold)
    stopifnot(ftr %in% colnames(fts.shape))
    inds <- which(fts.shape[, ftr] <= thr)
  }
  imclean <- rmObjects(x = imthreshold, index = inds)
  return(imclean)
}

# Define watershed function for later
watershed_cells <- function(imclean, tol = 0.1, verbose = FALSE) {
  if (class(imclean) != "Image") stop(paste0("Invalid input format: ", class(imclean)))
  if (verbose) cat("Applying watershed ... \n")
  imwatershed <- watershed(x = EBImage::distmap(imclean), tolerance = tol)
  return(imwatershed)
}

# Now we have a pretty decent workflow for segmenting cells so let’s combine the 5 steps into one function.
SegmentCells <- function(
  impath,
  crop.window = NULL,
  brush.size = 9,
  nsd = 2,
  feature = "s.area",
  feature.threshold = c(5, 40),
  do.fast = FALSE,
  tolerance = 0.1,
  return.all = FALSE,
  verbose = FALSE
) {
  if (!file.exists(impath)) stop(paste0("File ", impath, " does not exist \n"))
  cells <- readImage(impath)
  cells <- EBImage::normalize(cells)
  
  if (!is.null(crop.window)) {
    if (!length(crop.window) == 4 & class(crop.window) %in% c("numeric", "integer")) stop("Invalid crop window \n")
    cells <- cells[crop.window[1]:crop.window[2], crop.window[3]:crop.window[4]]
  }
  
  cells_filtered <- filter_cells(cells, brush.size, verbose) # 1. filter 
  cells_corrected <- correct_cells(cells, cells_filtered, verbose) # 2. correct 
  cells_th <- threshold_cells(cells_corrected, nsd, verbose) # 3. threshold
  cells_clean <- clean_cells(cells_th, feature, feature.threshold, do.fast, verbose) # 4. clean
  #cells_colored <- paintObjects(cells_clean, cells, col = "#FFA500")
  #display(cells_colored)
  cells_split <- watershed_cells(cells_clean, tolerance, verbose) # 5. watershed
  
  if (return.all) {
    return(list(cells, cells_filtered, cells_corrected, cells_clean, cells_split))
  } else {
    return(cells_split)
  }
}

# Define overlap function
# select cells based on an overlap criteria to make sure that shapes that are split into multiple new shapes are not all included in the output
# Only the shape with the highest overlap is kept and the overlap also have to be above a specified threshold (e.g. 50%)
# The overlap between two shapes is defined as the area of the intersect divided by the area of the smallest shape.
# for cells with multiple overlaps, keep only the top hit
# for each pair of overlapping shapes A and B, estimate the overlap as intersect(A, B)/min(A, B)
# return cells with an overlap of at least 50%

overlap_fkn <- function(x, y, i) {
  return(i/pmin(x, y))
}

OverlapImages <- function(
  ima, 
  imb, 
  overlap.min = 0.5, 
  return.merged = FALSE, 
  return.indices = FALSE, 
  verbose = FALSE
) {
  
  if (length(dim(ima)) == 3 | length(dim(imb)) == 3) {
    stop("Invalid dims for ima or imb")
  }
  if (length(table(ima)) <= 2) stop("ima has not been labeled")
  if (length(table(imb)) <= 2) stop("imb has not been labeled")
  # Summarize overlap across images
  if (verbose) cat(paste0("Calculating intersect between images \n"))
  d <- data.frame(a = as.numeric(ima), b = as.numeric(imb))
  d <- table(d) %>% as.matrix()
  d <- d[-1, -1]
  
  # Extract area for image a and image b
  area_a <- table(ima)[-1]
  aa <- setNames(as.numeric(area_a), names(area_a))
  area_b <- table(imb)[-1]
  ab <- setNames(as.numeric(area_b), names(area_b))
  if (verbose) cat(paste0("Finished calculating intersect between ", length(area_a), " shapes in image a and ", length(area_b), " shapes in image b \n"))
  
  # Collect indices for overlaping shapes
  intersect_ab <- which(d > 0, arr.ind = T)
  indices <- setNames(data.frame(apply(do.call(rbind, (lapply(1:nrow(intersect_ab), function(i) {
    inds <- intersect_ab[i, ]
    c(rownames(d)[inds[1]], colnames(d)[inds[2]], d[inds[1], inds[2]])
  }))), 2, function(x) as.character(x)), stringsAsFactors = F), nm = c("ind.a", "ind.b", "intersect"))
  
  # Collect shape areas, indices and intersect
  df <- data.frame(area.a = aa[indices$ind.a], area.b = ab[indices$ind.b], 
                   inda = as.integer(indices$ind.a), indb = as.integer(indices$ind.b), 
                   intersect = as.numeric(indices$intersect), stringsAsFactors = F)
  
  # Calculate overlap
  if (verbose) cat(paste0("Calculating overlap between images using shape intersect \n"))
  df$overlap <- overlap_fkn(x = df$area.a, y = df$area.b, i = df$intersect)
  df$keep <- df$overlap > overlap.min
  df <- subset(df, keep)
  
  # Clean up image a and image b
  ima_clean <- rmObjects(ima, index = setdiff(as.integer(names(table(ima)[-1])), df$inda))
  imb_clean <- rmObjects(imb, index = setdiff(as.integer(names(table(imb)[-1])), df$indb))
  
  # Should the clean images be merged?
  if (return.merged) {
    imres <- ima_clean | imb_clean
  } else {
    imres <- ima_clean & imb_clean
  }
  
  # return extra data
  if (return.indices) {
    return(list(bwlabel(imres), df))
  } else {
    return(bwlabel(imres))
  }
}
```

# Segmentation workflow

Apply previoulsy established segmentation workflow to uncropped and raw TIF images for each channel

```{r segmentation_run}

img.files.list <- list(
  v13 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V13", recursive = T, full.names = T),
  v14 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V14", recursive = T, full.names = T),
  v15 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V15", recursive = T, full.names = T),
  v16 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V16", recursive = T, full.names = T)
)

# Define feature threshold ranges
feature.thresholds <- list(Neun = c(5, 40), Olig2 = c(8, 40), Egfp = c(5, 40))
img.files.list <- lapply(img.files.list, function(x) {
  setNames(x, nm = c("Egfp", "Neun", "Olig2"))
})

segmented.list <- list()
for (s in names(img.files.list)) {
  img.files <- img.files.list[[s]]
  segmented <- list()
  for (i in 1:length(img.files)) {
    target <- names(img.files)[i]
    segmented[[i]] <- SegmentCells(
      impath = img.files[i], 
      crop.window = NULL, # x axis crop between pos1 and pos2, y axis crop between pos3 and pos4
      nsd = 2, 
      feature.threshold = feature.thresholds[[target]], 
      do.fast = TRUE, 
      verbose = TRUE)
  }
  names(segmented) <- c("Egfp", "Neun", "Olig2")
  segmented.list[[s]] <- segmented
}

```

# Find overlapping signals

The next step will be to find out what signals are overlapping, but first we can just visualize the results from the three segmented images. Since we have three targets, we can encode them directly in RGB channels. You can already see some overlapping cells. We can ignore the cells along the edges for now, these will not be present when we run the whole image at once.

```{r count_features}
for (s in names(segmented.list)) {
  segmented <- segmented.list[[s]]
  cat("Total number of oligodendrocytes in ", s, ": ", length(table(segmented[["Olig2"]])), "\n")
  cat("Total number of EGFP in ", s, ": ", length(table(segmented[["Egfp"]])), "\n")
  cat("Total number of neurons in ", s, ": ", length(table(segmented[["Neun"]])), "\n\n")
}


```

# Display combined stainings
```{r combined_stains, fig.height=12, fig.width=12}

for (segmented in segmented.list) {
  im <- rgbImage(red = segmented[["Olig2"]], green = segmented[["Egfp"]], blue = segmented[["Neun"]])
  display(im, method = "raster")
  text(x = 10, y = 20, label = "combined stainings", adj = c(0, 1), col = "orange", cex = 1.5)
}

```

# estimate intersect of overlapping cells

for cells with multiple overlaps, keep only the top hit
for each pair of overlapping shapes A and B, estimate the overlap as intersect(A, B)/min(A, B)
return cells with an overlap of at least 50%

Now we can apply this overlap detection tool to pairs of segmented images. Remember that the segmented images are stored as different color channels in the object “im”, where red = Olig2, green = Egfp and blue = Neun.

The unknown Egfp cells are here defined as the Egfp cells with neither Olig2 or Neun overlap. This still means that there could be some overlap, just smaller than 50%.


```{r overlap_computation, fig.height=6, fig.width=6}

segmented.egfp.list <- list()
for (s in names(segmented.list)) {
  segmented <- segmented.list[[s]]
  
  # overlap between olig2 and neun
  c(olig2_neun, Olig2_Neun_inds) %<-% OverlapImages(segmented[["Olig2"]], segmented[["Neun"]], return.indices = T)
  Olig2 <- rmObjects(segmented[["Olig2"]], index = Olig2_Neun_inds$inda)
  Neun <- rmObjects(segmented[["Neun"]], index = Olig2_Neun_inds$indb)
  
  # overlap between olig2 and egfp
  c(oligodendrocytes, Olig2_inds) %<-% OverlapImages(Olig2, segmented[["Egfp"]], return.indices = T)
  
  #overlap between neun and egfp
  c(neurons, Neun_inds) %<-% OverlapImages(Neun, segmented[["Egfp"]], return.indices = T)
  
  # overlap between olig2_neun and egfp
  c(oligodendrocytes_neurons, oligodendrocytes_neurons_inds) %<-% OverlapImages(olig2_neun, segmented[["Egfp"]], return.indices = T)
  
  # egfp only
  unknown <- rmObjects(segmented[["Egfp"]], index = as.numeric(c(Olig2_inds$indb, Neun_inds$indb)))
  
  segmented.egfp.list[[s]] <- list(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown)
  cat("Finished processing dataset ", s, "\n")
}

```


```{r estimate_counts}

for (s in names(segmented.egfp.list)) {
  c(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown) %<-% segmented.egfp.list[[s]]
  
  fts.moment.neurons <- computeFeatures.moment(neurons)
  cat(s, ": Total number of estimated Egfp+ neurons: ", nrow(fts.moment.neurons), "\n")
  
  fts.moment.oligodenrocytes <- computeFeatures.moment(oligodendrocytes)
  cat(s, ": Total number of estimated Egfp+ oligodendrocytes: ", nrow(fts.moment.oligodenrocytes), "\n")
  
  fts.moment.olig2_neun_egfp <- computeFeatures.moment(oligodendrocytes_neurons)
  cat(s, ": Total number of overlapping Neun-Olig2-EGFP: ", nrow(fts.moment.olig2_neun_egfp), "\n")
  
  fts.moment.unknown <- computeFeatures.moment(unknown)
  cat(s, ": Total number of Egfp+ unknown: ", nrow(fts.moment.unknown), "\n")
  
  cat(s, ": Total number of Egfp+ cells after cleaning: ", nrow(fts.moment.neurons) + nrow(fts.moment.oligodenrocytes) + nrow(fts.moment.unknown), "\n\n")
}

```


Total number of Egfp+ cells after cleaning:  3758

We can now extract the feature coordinates and labels to have a data.frame format that is a bit easier to work with

```{r pot_celltypes, fig.width=14, fig.height=12}

df.neurons <- data.frame()
df.oligo <- data.frame()
df.oligo_neurons <- data.frame()
df.unknown <- data.frame()

for (i in seq_along(segmented.egfp.list)) {
  c(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown) %<-% segmented.egfp.list[[i]]
  fts.moment.neurons <- computeFeatures.moment(neurons)
  df.neurons <- rbind(df.neurons, setNames(cbind(data.frame(fts.moment.neurons[, 1:2]), "neuron", sample = i), nm = c("x", "y", "celltype", "sample")))
  
  fts.moment.oligodenrocytes <- computeFeatures.moment(oligodendrocytes)
  df.oligo <- rbind(df.oligo, setNames(cbind(data.frame(fts.moment.oligodenrocytes[, 1:2]), "oligo", sample = i), nm = c("x", "y", "celltype", "sample")))
  
  fts.moment.olig2_neun_egfp <- computeFeatures.moment(oligodendrocytes_neurons)
  df.oligo_neurons <- rbind(df.oligo_neurons, setNames(cbind(data.frame(fts.moment.olig2_neun_egfp[, 1:2]), "oligo_neurons", sample = i), nm = c("x", "y", "celltype", "sample")))
  
  fts.moment.unknown <- computeFeatures.moment(unknown)
  df.unknown <- rbind(df.unknown, setNames(cbind(data.frame(fts.moment.unknown[, 1:2]), "unknown", sample = i), nm = c("x", "y", "celltype", "sample")))
}
  
```

Now we can read the spot coordinates and convert them to fit the "tissue_hires_image.png" using the "tissue_hires_scalef" scaling factor.

<br>
```{r load_spots}

# Read spot coordinates
positions.files <- c("data/spaceranger/V13/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V14/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V15/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V16/spatial/tissue_positions_list.csv")

spots <- lapply(positions.files, function(positions) {
  setNames(read.table(positions, header = F, sep = ","), c("barcode", "selection", "y", "x", "pixel_y", "pixel_x"))
})

# Read json file containing scaling factors
scalefactors.files <- c("data/spaceranger/V13/spatial/scalefactors_json.json",
                        "data/spaceranger/V14/spatial/scalefactors_json.json",
                        "data/spaceranger/V15/spatial/scalefactors_json.json",
                        "data/spaceranger/V16/spatial/scalefactors_json.json")

spots <- setNames(lapply(seq_along(spots), function(i) {
  x <- spots[[i]]
  scaleVisium <- jsonlite::read_json(scalefactors.files[i])
  x[, c("pixel_x", "pixel_y")] <- x[, c("pixel_x", "pixel_y")]*scaleVisium$tissue_hires_scalef
  x <- subset(x, selection == 1)
  return(x)
}), nm = c("v13", "v14", "v15", "v16"))

# Get pixels per micron from known image size and number of pixels
image.size.micron <- 8705 
image.size.pixel <- 2000
pixels.per.um <- image.size.pixel/image.size.micron

# Spot radius = 55um/2
spot.radius <- pixels.per.um*27.5
cat("spot radius: ", spot.radius)

```
<br>

# Check that spots are aligned with IF

# neurons

<br>
```{r plot_results, fig.height=12, fig.width=12, out.width="100%"}

par(mfrow = c(2, 2), mar=c(0,0,0,0))
for (s in names(segmented.egfp.list)) {
  c(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown) %<-% segmented.egfp.list[[s]]
  fts.moment.neurons <- computeFeatures.moment(neurons)
  resize <- dim(neurons)[2]/2000
  print(resize)
  gg <- fts.moment.neurons[, 1:2]/resize
  plot(x = spots[[s]]$pixel_x, y = 2000 - spots[[s]]$pixel_y, xlim = c(0, 2000), ylim = c(0, 2000), axes=FALSE)
  points(gg[, 1], 2000 - gg[, 2], col = "red", pch = 19, cex=0.5)
}

```

# Alignment of images

```{r alignment}

library(STutility)

# Get HE images
he.images <- list.files(pattern = "neun.tif", path = "data", recursive = TRUE, full.names = TRUE)[2:5]

for (he in he.images) {
  img <- readImage(he)
  img <- normalize(img)
  writeImage(x = img, files = paste0(dirname(he), "/neun_mod.jpg"))
}


he.images <- list.files(pattern = "neun_mod.jpg", path = "data", recursive = TRUE, full.names = TRUE)
json <- list.files(pattern = "scalefactors", path = "data/spaceranger", recursive = TRUE, full.names = TRUE)[4:7]

# Get spot meta.data
spotfiles <- list.files(pattern = "tissue_positions", path = "data/spaceranger", recursive = TRUE, full.names = TRUE)[4:7]
meta.data <- do.call(rbind, lapply(seq_along(spotfiles), function(i) {
  alignment <- read.table(file = spotfiles[i], header = FALSE, sep = ",", stringsAsFactors = FALSE)
  alignment <- setNames(alignment, nm = c("barcode", "selection", "y", "x", "pixel_y", "pixel_x"))
  sf <- jsonlite::read_json(path = json[i])$tissue_hires_scalef*resize
  alignment$pixel_x <- alignment$pixel_x*sf
  alignment$pixel_y <- alignment$pixel_y*sf
  alignment <- subset(alignment, selection == 1)
  alignment <- data.frame(x = alignment$x, y = alignment$y, adj_x = alignment$x, adj_y = alignment$y,
                          pixel_x = alignment$pixel_x, pixel_y = alignment$pixel_y, barcode = alignment$barcode,
                          sample = paste0(i), stringsAsFactors = FALSE)
  rownames(alignment) <- paste0(alignment$x, "x", alignment$y, "_", i)
  return(alignment)
}))

st.object <- CreateStaffliObject(imgs = he.images, meta.data = meta.data, xdim = 400, platforms = rep("Visium", 4))
st.object <- LoadImages(st.object, time.resolve = FALSE, verbose = TRUE)

# Define slic function
slic <- function (im, nS, compactness = 1) {
  #if (imager::spectrum(im) == 3) im <- imager::sRGBtoLab(im)
  sc.spat <- (dim(im)[1:2]*.28) %>% max
  sc.col <- imager::imsplit(im, "c") %>% purrr::map_dbl(sd) %>% max
  rat <- (sc.spat/sc.col)/(compactness*10)
  X <- as.data.frame(im*rat, wide = "c") %>% as.matrix
  ind <- round(seq(1, imager::nPix(im)/imager::spectrum(im), l = nS))
  km <- suppressWarnings({kmeans(X, X[ind, ])})
  sp <- purrr::map(1:imager::spectrum(im), ~ km$centers[km$cluster, 2+.]) %>% do.call(c, .) %>% imager::as.cimg(dim = dim(im))
  sp <- sp/rat
  if (imager::spectrum(im) == 3) {
    sp <- imager::LabtosRGB(sp)
  }
  return(sp)
}

# Define mask function
msk_fkn <- function (im) {
  im[im < mean(EBImage::otsu(im)*0.9)] <- 0
  im <- imager::medianblur(im, n = 14)
  out <- slic(im, nS = 600, compactness = 1)
  d <- imager::sRGBtoLab(out) %>% as.data.frame(wide = "c") %>%
        dplyr::select(-x, -y)

  km <- kmeans(d, 2)
  seg <- imager::as.cimg(km$cluster - 1, dim = c(dim(im)[1:2], 1, 1)) %>% imager::threshold()
}

st.object <- MaskImages(st.object, custom.msk.fkn = msk_fkn, verbose = TRUE)
st.object <- AlignImages(st.object, verbose = TRUE)

par(mfrow = c(2, 2))
for (i in 1:4) {
  plot(as.cimg(st.object@rasterlists$processed.masks[[1]]))
  points(subset(st.object@meta.data[, c("pixel_x", "pixel_y")]/(2000/400)))
}

```

Apply transformation to segmented output

```{r transform_seg, fig.height=6, fig.width=6}

# Define map fkn
generate.map.affine <- function (
  tr, 
  forward = FALSE
) {
  if (forward) {
    map.affine <- function (x, y) {
      p <- cbind(x, y)
      xy <- t(solve(tr)%*%t(cbind(p, 1)))
      list(x = xy[, 1], y = xy[, 2])
    }
  } else {
    map.affine <- function (x, y) {
      p <- cbind(x, y)
      xy <- t(tr%*%t(cbind(p, 1)))
      list(x = xy[, 1], y = xy[, 2])
    }
  }
  return(map.affine)
}

WarpCoords <- function (
  st.object, df
) {
  df <- df[, 1:4]
  df <- cbind(df, data.frame(warped_x = NA, warped_y = NA))
  for (i in seq_along(st.object@samplenames)) {
    dims.raw <- st.object@dims[[i]][, c("width", "height")] %>% as.numeric()
    dims.scaled <- scaled.imdims(st.object)[[i]]
    sf.xy <- dims.raw[2]/dims.scaled[1]
    
    tr <- st.object@transformations[[i]]
    map.affine.forward <- generate.map.affine(tr, forward = TRUE)
    df_subset <- subset(df, sample == i)
    df_subset[, c("x", "y")] <- df_subset[, c("x", "y")]/sf.xy
    warped_xy <- do.call(cbind, map.affine.forward(x = df_subset$x, y = df_subset$y))
    warped_xy <- warped_xy*sf.xy
    df[df$sample == i, c("warped_x", "warped_y")] <- warped_xy
  }
  return(df)
}

dfs <- list(neurons = df.neurons, oligo = df.oligo, olig_neurons = df.oligo_neurons, unknown = df.unknown)
dfs <- lapply(dfs, function(df) {
  df <- WarpCoords(st.object, df)
})

```


```{r plot_seg_vs_aligned}

set1 = st.object@meta.data[, c("warped_x", "warped_y", "sample")]
set1$z <- pixels.per.um*12*as.numeric(set1$sample)
set1 <- set1[, c("warped_x", "warped_y", "z")]
set.list <- lapply(seq_along(dfs), function(i) {
  df <- dfs[[i]]
  set2 = df[, c("warped_x", "warped_y", "sample")]
  set2$z <- set2$sample*pixels.per.um*12
  set2 <- set2[, c("warped_x", "warped_y", "z")]
})

par(mfrow = c(2, 2))
for(i in 1:4) {
  d <- dim(segmented.egfp.list[[i]][[1]])[2]
  plot(subset(set1, sample == i)[, 1:2], xlim = c(0, d), ylim = c(0, d), axes=F)
  points(subset(set2, sample == i)[, 1:2], col = "red", cex=0.2)
}

```


## Distance

Calculate distances between nuclei and Visium spots

<br>
```{r distance}

mindists <- lapply(set.list, function(set2) {
  mindist <- apply(set1, 1, function(x) {
    sqrt(colSums((t(set2) - x)^2))
  })
})


# spot radius in microns
sp.rad <- 27.5

# cell radius in microns
cell.rad <- 25

# Set threshold
thr <- pixels.per.um*sp.rad + pixels.per.um*cell.rad

# plot
hist(mindists[[1]], breaks = 100)
abline(v = thr, lty = "longdash", col = "red")

# Set all distances < thr to 0
#mindists[mindists > thr] <- NA
res.list <- lapply(seq_along(mindists), function(i) {
  df <- dfs[[i]]
  mindist <- mindists[[i]]
  ctype <- as.character(df$celltype)
  spts <- as.character(st.object@meta.data$barcode)
  res <- do.call(rbind, lapply(1:ncol(mindist), function(i) {
    x <- mindist[, i]
    inds = which(x <= thr)
    if (length(inds) > 0) {
      return(data.frame(celltype = ctype[inds], pixel_x_nuclei = df$warped_x[inds], 
                        pixel_y_nuclei = df$warped_y[inds], barcode = spts[i], 
                        sample = df$sample[inds], stringsAsFactors = F))
    } else {
      return(NULL)
    }
  }))
})

```

```{r 3D}

all.cells <- do.call(rbind, res.list)

library(plotly)
plot_ly(subset(all.cells, !celltype %in% "unknown"), x = ~pixel_x_nuclei, y = ~pixel_y_nuclei, z = ~sample, color = ~celltype, size = 0.2)

```

