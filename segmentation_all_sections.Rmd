---
title: "cell_segmentation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libs}
library(EBImage)
library(ggplot2)
library(cowplot)
library(magrittr)
library(zeallot)
library(dplyr)
library(plotly)
```

# Define functions
***

```{r define_functions}
# Define filter function for later
filter_cells <- function(im, brush.size = 9, verbose = FALSE) {
  if (verbose) cat("Applying 2D convolution filter to image ... \n")
  f = makeBrush(brush.size, shape = 'disc', step = FALSE)
  f = f/sum(f)
  imfiltered <- filter2(im, filter = f)
  return(imfiltered)
}


# Define correction function for later
correct_cells <- function(im, imfiltered, verbose = FALSE) {
  if (class(im) != "Image") stop(paste0("Invalid input format of im: ", class(im)))
  if (class(imfiltered) != "Image") stop(paste0("Invalid input format of imfiltered: ", class(imfiltered)))
  if (verbose) cat("Correcting image ... \n")
  imcorrected <- (im - imfiltered) %>% normalize()
  return(imcorrected)
}

# Define threshold function for later
threshold_cells <- function(imcorrected, nsd = 2, verbose = FALSE) {
  if (class(imcorrected) != "Image") stop(paste0("Invalid input format: ", class(imcorrected)))
  if (verbose) cat("Thresholding cells ... \n")
  thr <- mean(imcorrected) + nsd*sd(imcorrected)
  imthreshold <- imcorrected > thr
  return(imthreshold)
}

# Define cleaning function for later
clean_cells <- function(imthreshold, ftr = "s.area", thr = c(5, 40), do.fast = FALSE, verbose = FALSE) {
  if (class(imthreshold) != "Image") stop(paste0("Invalid input format: ", class(imthreshold)))
  if (verbose) cat("Cleaning up unwanted speckles ... \n")
  imthreshold <- bwlabel(imthreshold)
  if (do.fast & ftr == "s.area") {
    areas <- table(imthreshold)[-1]
    inds <- which(areas < thr[1] | areas > thr[2])
  } else if (do.fast & ftr != "s.area") (
    stop(paste0("Invalid option ", ftr, " for ftr. Only ftr = 's.area' can be used for fast shape extraction."))
  ) else {
    fts.shape <- shape_extractor(x = imthreshold)
    stopifnot(ftr %in% colnames(fts.shape))
    inds <- which(fts.shape[, ftr] <= thr)
  }
  imclean <- rmObjects(x = imthreshold, index = inds)
  return(imclean)
}

# Define watershed function for later
watershed_cells <- function(imclean, tol = 0.1, verbose = FALSE) {
  if (class(imclean) != "Image") stop(paste0("Invalid input format: ", class(imclean)))
  if (verbose) cat("Applying watershed ... \n")
  imwatershed <- watershed(x = EBImage::distmap(imclean), tolerance = tol)
  return(imwatershed)
}

# Now we have a pretty decent workflow for segmenting cells so let’s combine the 5 steps into one function.
SegmentCells <- function(
  impath,
  crop.window = NULL,
  brush.size = 9,
  nsd = 2,
  feature = "s.area",
  feature.threshold = c(5, 40),
  do.fast = FALSE,
  tolerance = 0.1,
  return.all = FALSE,
  verbose = FALSE
) {
  if (!file.exists(impath)) stop(paste0("File ", impath, " does not exist \n"))
  cells <- readImage(impath)
  cells <- EBImage::normalize(cells)
  
  if (!is.null(crop.window)) {
    if (!length(crop.window) == 4 & class(crop.window) %in% c("numeric", "integer")) stop("Invalid crop window \n")
    cells <- cells[crop.window[1]:crop.window[2], crop.window[3]:crop.window[4]]
  }
  
  cells_filtered <- filter_cells(cells, brush.size, verbose) # 1. filter 
  cells_corrected <- correct_cells(cells, cells_filtered, verbose) # 2. correct 
  cells_th <- threshold_cells(cells_corrected, nsd, verbose) # 3. threshold
  cells_clean <- clean_cells(cells_th, feature, feature.threshold, do.fast, verbose) # 4. clean
  #cells_colored <- paintObjects(cells_clean, cells, col = "#FFA500")
  #display(cells_colored)
  cells_split <- watershed_cells(cells_clean, tolerance, verbose) # 5. watershed
  
  if (return.all) {
    return(list(cells, cells_filtered, cells_corrected, cells_clean, cells_split))
  } else {
    return(cells_split)
  }
}

# Define overlap function
# select cells based on an overlap criteria to make sure that shapes that are split into multiple new shapes are not all included in the output
# Only the shape with the highest overlap is kept and the overlap also have to be above a specified threshold (e.g. 50%)
# The overlap between two shapes is defined as the area of the intersect divided by the area of the smallest shape.
# for cells with multiple overlaps, keep only the top hit
# for each pair of overlapping shapes A and B, estimate the overlap as intersect(A, B)/min(A, B)
# return cells with an overlap of at least 50%

overlap_fkn <- function(x, y, i) {
  return(i/pmin(x, y))
}

OverlapImages <- function(
  ima, 
  imb, 
  overlap.min = 0.5, 
  return.merged = FALSE, 
  return.indices = FALSE, 
  verbose = FALSE
) {
  
  if (length(dim(ima)) == 3 | length(dim(imb)) == 3) {
    stop("Invalid dims for ima or imb")
  }
  if (length(table(ima)) <= 2) stop("ima has not been labeled")
  if (length(table(imb)) <= 2) stop("imb has not been labeled")
  # Summarize overlap across images
  if (verbose) cat(paste0("Calculating intersect between images \n"))
  d <- data.frame(a = as.numeric(ima), b = as.numeric(imb))
  d <- table(d) %>% as.matrix()
  d <- d[-1, -1]
  
  # Extract area for image a and image b
  area_a <- table(ima)[-1]
  aa <- setNames(as.numeric(area_a), names(area_a))
  area_b <- table(imb)[-1]
  ab <- setNames(as.numeric(area_b), names(area_b))
  if (verbose) cat(paste0("Finished calculating intersect between ", length(area_a), " shapes in image a and ", length(area_b), " shapes in image b \n"))
  
  # Collect indices for overlaping shapes
  intersect_ab <- which(d > 0, arr.ind = T)
  indices <- setNames(data.frame(apply(do.call(rbind, (lapply(1:nrow(intersect_ab), function(i) {
    inds <- intersect_ab[i, ]
    c(rownames(d)[inds[1]], colnames(d)[inds[2]], d[inds[1], inds[2]])
  }))), 2, function(x) as.character(x)), stringsAsFactors = F), nm = c("ind.a", "ind.b", "intersect"))
  
  # Collect shape areas, indices and intersect
  df <- data.frame(area.a = aa[indices$ind.a], area.b = ab[indices$ind.b], 
                   inda = as.integer(indices$ind.a), indb = as.integer(indices$ind.b), 
                   intersect = as.numeric(indices$intersect), stringsAsFactors = F)
  
  # Calculate overlap
  if (verbose) cat(paste0("Calculating overlap between images using shape intersect \n"))
  df$overlap <- overlap_fkn(x = df$area.a, y = df$area.b, i = df$intersect)
  df$keep <- df$overlap > overlap.min
  df <- subset(df, keep)
  
  # Clean up image a and image b
  ima_clean <- rmObjects(ima, index = setdiff(as.integer(names(table(ima)[-1])), df$inda))
  imb_clean <- rmObjects(imb, index = setdiff(as.integer(names(table(imb)[-1])), df$indb))
  
  # Should the clean images be merged?
  if (return.merged) {
    imres <- ima_clean | imb_clean
  } else {
    imres <- ima_clean & imb_clean
  }
  
  # return extra data
  if (return.indices) {
    return(list(bwlabel(imres), df))
  } else {
    return(bwlabel(imres))
  }
}
```

# Segmentation workflow

Apply previoulsy established segmentation workflow to uncropped and raw TIF images for each channel

```{r segmentation_run}

# list input files
img.files.list <- list(
  v13 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V13", recursive = T, full.names = T),
  v14 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V14", recursive = T, full.names = T),
  v15 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V15", recursive = T, full.names = T),
  v16 = list.files(pattern = "olig2.tif|neun.tif|egfp.tif", path = "data/V16", recursive = T, full.names = T)
)

# define feature threshold ranges
feature.thresholds <- list(Neun = c(5, 40), Olig2 = c(8, 40), Egfp = c(5, 40))
img.files.list <- lapply(img.files.list, function(x) {
  setNames(x, nm = c("Egfp", "Neun", "Olig2"))
})

# read images and run segmentation for each dataset
segmented.list <- list()
for (s in names(img.files.list)) {
  img.files <- img.files.list[[s]]
  segmented <- list()
  for (i in 1:length(img.files)) {
    target <- names(img.files)[i]
    segmented[[i]] <- SegmentCells(
      impath = img.files[i], 
      crop.window = NULL, # x axis crop between pos1 and pos2, y axis crop between pos3 and pos4
      nsd = 2, 
      feature.threshold = feature.thresholds[[target]], 
      do.fast = TRUE, 
      verbose = TRUE)
  }
  names(segmented) <- c("Egfp", "Neun", "Olig2")
  segmented.list[[s]] <- segmented
}

```

## Count detected nuclei
***

```{r count_features}

for (s in names(segmented.list)) {
  segmented <- segmented.list[[s]]
  cat("Total number of oligodendrocytes in ", s, ": ", length(table(segmented[["Olig2"]])), "\n")
  cat("Total number of EGFP in ", s, ": ", length(table(segmented[["Egfp"]])), "\n")
  cat("Total number of neurons in ", s, ": ", length(table(segmented[["Neun"]])), "\n\n")
}

```

## Display combined stainings
***

Something looks really odd in sample 2, like the brain section has been torn apart a little. There's almost no signal for Olig2 and Neun, but wuite a lot for Egfp.

```{r combined_stains, fig.height=12, fig.width=12}

for (i in seq_along(segmented.list)) {
  segmented <- segmented.list[[i]]
  im <- rgbImage(red = segmented[["Olig2"]], green = segmented[["Egfp"]], blue = segmented[["Neun"]])
  display(im, method = "raster")
  text(x = 10, y = 20, label = paste0("section ", i, "\nred : Olig2, green : Egfp, blue : Neun"), adj = c(0, 1), col = "orange", cex = 1.5)
}

```

# estimate intersect of overlapping cells
***

for cells with multiple overlaps, keep only the top hit
for each pair of overlapping shapes A and B, estimate the overlap as intersect(A, B)/min(A, B)
return cells with an overlap of at least 50%

Now we can apply this overlap detection tool to pairs of segmented images. Remember that the segmented images are stored as different color channels in the object “im”, where red = Olig2, green = Egfp and blue = Neun.

The unknown Egfp cells are here defined as the Egfp cells with neither Olig2 or Neun overlap. This still means that there could be some overlap, just smaller than 50%.

1. Run overlap function on Olig2 and Neun images to find cells with Olig2+ and Neun+ signal
2. Remove overlapping cells defined in (1) from Olig2 and Neun images
3. Run overlap function on Olig2 and Egfp images to find cells with Olig2+ and Egfp+ signal
4. Run overlap function on Neun and Egfp images to find cells with Neun+ and Egfp+ signal
5. Run overlap function on Olig2_Neun defined in (1) and Egfp images to find cells with Neun+, Olig2+ and Egfp+ signal
6. Define unknown cells as all Egfp+ cells which are not in (3) or (4). This should still include cells which are positive for all three signals

```{r overlap_computation, fig.height=6, fig.width=6}

segmented.egfp.list <- list()
for (s in names(segmented.list)) {
  segmented <- segmented.list[[s]]
  
  # overlap between olig2 and neun
  c(olig2_neun, Olig2_Neun_inds) %<-% OverlapImages(segmented[["Olig2"]], segmented[["Neun"]], return.indices = T) # 1.
  Olig2 <- rmObjects(segmented[["Olig2"]], index = Olig2_Neun_inds$inda) # 2.
  Neun <- rmObjects(segmented[["Neun"]], index = Olig2_Neun_inds$indb) # 2.
  
  # overlap between olig2 and egfp
  c(oligodendrocytes, Olig2_inds) %<-% OverlapImages(Olig2, segmented[["Egfp"]], return.indices = T) # 3.
  
  #overlap between neun and egfp
  c(neurons, Neun_inds) %<-% OverlapImages(Neun, segmented[["Egfp"]], return.indices = T) # 4.
  
  # overlap between olig2_neun and egfp
  c(oligodendrocytes_neurons, oligodendrocytes_neurons_inds) %<-% OverlapImages(olig2_neun, segmented[["Egfp"]], return.indices = T) # 5.
  
  # egfp only
  unknown <- rmObjects(segmented[["Egfp"]], index = as.numeric(c(Olig2_inds$indb, Neun_inds$indb))) # 6.
  
  segmented.egfp.list[[s]] <- list(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown)
  cat("Finished processing dataset ", s, "\n")
}

```

## Count Egfp+ nuclei
***

```{r estimate_counts}

for (s in names(segmented.egfp.list)) {
  c(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown) %<-% segmented.egfp.list[[s]]
  
  fts.moment.neurons <- computeFeatures.moment(neurons)
  cat(s, ": Total number of estimated Egfp+ neurons: ", nrow(fts.moment.neurons), "\n")
  
  fts.moment.oligodenrocytes <- computeFeatures.moment(oligodendrocytes)
  cat(s, ": Total number of estimated Egfp+ oligodendrocytes: ", nrow(fts.moment.oligodenrocytes), "\n")
  
  fts.moment.olig2_neun_egfp <- computeFeatures.moment(oligodendrocytes_neurons)
  cat(s, ": Total number of overlapping Neun-Olig2-EGFP: ", nrow(fts.moment.olig2_neun_egfp), "\n")
  
  fts.moment.unknown <- computeFeatures.moment(unknown)
  cat(s, ": Total number of Egfp+ unknown: ", nrow(fts.moment.unknown), "\n")
  
  cat(s, ": Total number of Egfp+ cells after cleaning: ", nrow(fts.moment.neurons) + nrow(fts.moment.oligodenrocytes) + nrow(fts.moment.unknown), "\n\n")
}

```

We can now extract the feature coordinates and labels to have a data.frame format that is a bit easier to work with. Each data.frame contains the x/y coordinates for a celltype and the sample column defines the sectioning order which we can use to set a z axis value.

```{r pot_celltypes, fig.width=14, fig.height=12}

df.neurons <- data.frame()
df.oligo <- data.frame()
df.oligo_neurons <- data.frame()
df.unknown <- data.frame()

segmented.egfp.list <- readRDS("R_objects/segmented.egfp.list")

for (i in seq_along(segmented.egfp.list)) {
  c(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown) %<-% segmented.egfp.list[[i]]
  fts.moment.neurons <- computeFeatures.moment(neurons)
  df.neurons <- rbind(df.neurons, setNames(cbind(data.frame(fts.moment.neurons[, 1:2]), "neuron", sample = i), nm = c("x", "y", "celltype", "sample")))
  
  fts.moment.oligodenrocytes <- computeFeatures.moment(oligodendrocytes)
  df.oligo <- rbind(df.oligo, setNames(cbind(data.frame(fts.moment.oligodenrocytes[, 1:2]), "oligo", sample = i), nm = c("x", "y", "celltype", "sample")))
  
  fts.moment.olig2_neun_egfp <- computeFeatures.moment(oligodendrocytes_neurons)
  df.oligo_neurons <- rbind(df.oligo_neurons, setNames(cbind(data.frame(fts.moment.olig2_neun_egfp[, 1:2]), "oligo_neurons", sample = i), nm = c("x", "y", "celltype", "sample")))
  
  fts.moment.unknown <- computeFeatures.moment(unknown)
  df.unknown <- rbind(df.unknown, setNames(cbind(data.frame(fts.moment.unknown[, 1:2]), "unknown", sample = i), nm = c("x", "y", "celltype", "sample")))
}

head(df.neurons)
  
```

Now we can read the spot coordinates and convert them to fit the "tissue_hires_image.png" using the "tissue_hires_scalef" scaling factor. We will load this spot coordinates from all four datasets and store them in a list of data.frames called spots. We have to subset the data to contain spots under tissue by keeping spots where the selection column is 1. The spots data.frames also contains the spot barcodes which we can use as a unique ID to keep track of the spots across different sections. However, first we need to make these IDs unique across section by adding some section-specific label.

NOTE that I have included all 8 sections here, but only sections v13-v16 will be used for analyses together with the segmented results.

<br>
```{r load_spots}

# Read spot coordinates
positions.files <- c("data/spaceranger/V9/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V10/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V11/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V12/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V13/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V14/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V15/spatial/tissue_positions_list.csv",
                     "data/spaceranger/V16/spatial/tissue_positions_list.csv")

spots <- lapply(positions.files, function(positions) {
  setNames(read.table(positions, header = F, sep = ","), c("barcode", "selection", "y", "x", "pixel_y", "pixel_x"))
})

# Read json file containing scaling factors
scalefactors.files <- c("data/spaceranger/V9/spatial/scalefactors_json.json",
                        "data/spaceranger/V10/spatial/scalefactors_json.json",
                        "data/spaceranger/V11/spatial/scalefactors_json.json",
                        "data/spaceranger/V12/spatial/scalefactors_json.json",
                        "data/spaceranger/V13/spatial/scalefactors_json.json",
                        "data/spaceranger/V14/spatial/scalefactors_json.json",
                        "data/spaceranger/V15/spatial/scalefactors_json.json",
                        "data/spaceranger/V16/spatial/scalefactors_json.json")

spots <- setNames(lapply(seq_along(spots), function(i) {
  x <- spots[[i]]
  scaleVisium <- jsonlite::read_json(scalefactors.files[i])
  x[, c("pixel_x", "pixel_y")] <- x[, c("pixel_x", "pixel_y")]*scaleVisium$tissue_hires_scalef
  x <- subset(x, selection == 1)
  x$barcode <- paste0(x$barcode, "_", i) # Add section label
  return(x)
}), nm = c("v9", "v10", "v11", "v12", "v13", "v14", "v15", "v16"))

# Get pixels per micron from known image size and number of pixels
image.size.micron <- 8705 
image.size.pixel <- 2000
pixels.per.um <- image.size.pixel/image.size.micron

# Spot radius = 55um/2
spot.radius <- pixels.per.um*27.5
cat("spot radius: ", spot.radius)

head(spots[[1]])

```
<br>

# Check that spots are aligned with IF

<br>
```{r plot_results, fig.height=12, fig.width=12, out.width="100%"}

par(mfrow = c(4, 4), mar = c(0.05, 0.05, 0.05, 0.05))
for (s in names(segmented.egfp.list)) {
  c(oligodendrocytes, neurons, oligodendrocytes_neurons, unknown) %<-% segmented.egfp.list[[s]]
  fts.moment.oligodendrocytes <- computeFeatures.moment(oligodendrocytes)
  fts.moment.neurons <- computeFeatures.moment(neurons)
  fts.moment.oligodendrocytes_neurons <- computeFeatures.moment(oligodendrocytes_neurons)
  fts.moment.unknown <- computeFeatures.moment(unknown)
  resize <- dim(neurons)[2]/2000
  
  # Plot oligodendrocytes
  gg <- fts.moment.oligodendrocytes[, 1:2]/resize
  plot(x = spots[[s]]$pixel_x, y = 2000 - spots[[s]]$pixel_y, xlim = c(0, 2000), ylim = c(0, 2000), axes=FALSE)
  points(gg[, 1], 2000 - gg[, 2], col = "red", pch = 19, cex=0.5)
  title(main = paste0("Oligodendrocytes ", s))
  
  # Plot neurons
  gg <- fts.moment.neurons[, 1:2]/resize
  plot(x = spots[[s]]$pixel_x, y = 2000 - spots[[s]]$pixel_y, xlim = c(0, 2000), ylim = c(0, 2000), axes=FALSE)
  points(gg[, 1], 2000 - gg[, 2], col = "blue", pch = 19, cex=0.5)
  title(main = paste0("Neurons ", s))
  
  # Plot neurons
  gg <- fts.moment.oligodendrocytes_neurons[, 1:2]/resize
  plot(x = spots[[s]]$pixel_x, y = 2000 - spots[[s]]$pixel_y, xlim = c(0, 2000), ylim = c(0, 2000), axes=FALSE)
  points(gg[, 1], 2000 - gg[, 2], col = "green", pch = 19, cex=0.5)
  title(main = paste0("Oligodendrocytes + Neurons ", s))
  
  # Plot neurons
  gg <- fts.moment.unknown[, 1:2]/resize
  plot(x = spots[[s]]$pixel_x, y = 2000 - spots[[s]]$pixel_y, xlim = c(0, 2000), ylim = c(0, 2000), axes=FALSE)
  points(gg[, 1], 2000 - gg[, 2], col = "yellow", pch = 19, cex=0.5)
  title(main = paste0("Unknowns ", s))
}

```

# Alignment of images
***

Here's we'll use the STUtility R package to find and apply a rigid alignment function to transform coordinates from a reference image to a target image. We would usually use the HE images for this, but in this case the Neun images worked quite well instead. i just had to normalize the intensity values and export the images as jpegs instead to make it work with the alignment functions.

Once we have the modified Neun images, we also need to load the spot coordinates to create a "Staffli" object. The Staffli object can be used to store image data and spot coordinates and we will use this object to find transformation function.

When creating the Staffli object using the `CreateStaffliObject` function we can set a parameter called xdim which will tdefine the width of the downscaled version of the original image that will be stored in the Staffli object. For example, if we set xdim to 400, the loaded images will be downscaled to a width of 400 pixels.

```{r alignment}

library(STutility)
library(EBImage)
setwd("~/Michael_Ratz/cell_segmentation/")

# Get Neun images for v13-v16
neun.images <- list.files(pattern = "neun.tif", path = "data", recursive = TRUE, full.names = TRUE)[2:5]

# Normalize intensity values and export as jpeg
for (neun in neun.images) {
  img <- readImage(neun)
  img <- normalize(img)
  writeImage(x = img, files = paste0(dirname(he), "/neun_mod.jpg"))
}

# List the paths to the modified jpegs
neun.images.mod <- list.files(pattern = "neun_mod.jpg", path = "data", recursive = TRUE, full.names = TRUE)
he.images <- list.files(pattern = "tissue_hires_image", path = "data", recursive = TRUE, full.names = TRUE)
he.images <- setNames(he.images, lapply(he.images, function(x) {
  (dirname(x) %>% strsplit("/"))[[1]][3]
}))
he.images <- he.images[paste0("v", 9:12)]

# Replace v13-v16 he images with modified Neun images
he.images <- c(he.images, setNames(neun.images.mod, nm = c("v13", "v14", "v15", "v16")))

# List scalefactor files
json <- list.files(pattern = "scalefactors", path = "data/spaceranger", recursive = TRUE, full.names = TRUE)
json <- setNames(json, lapply(json, function(x) {
  (dirname(x) %>% strsplit("/"))[[1]][3]
}))
json <- json[paste0("v", 9:16)]

# Create a data.frame with spot coordinates to use as meta.data for the Staffli object
spotfiles <- list.files(pattern = "tissue_positions", path = "data/spaceranger", recursive = TRUE, full.names = TRUE)
spotfiles <- setNames(spotfiles, lapply(spotfiles, function(x) {
  (dirname(x) %>% strsplit("/"))[[1]][3]
}))
spotfiles <- spotfiles[paste0("v", 9:16)]

meta.data.v9tov12 <- do.call(rbind, lapply(seq_along(spotfiles[1:4]), function(i) {
  alignment <- read.table(file = spotfiles[i], header = FALSE, sep = ",", stringsAsFactors = FALSE)
  alignment <- setNames(alignment, nm = c("barcode", "selection", "y", "x", "pixel_y", "pixel_x"))
  sf <- jsonlite::read_json(path = json[i])$tissue_hires_scalef
  alignment$pixel_x <- alignment$pixel_x*sf
  alignment$pixel_y <- alignment$pixel_y*sf
  alignment <- subset(alignment, selection == 1)
  alignment$barcode <- paste0(alignment$barcode, "_", i) # Add unique section label
  alignment <- data.frame(x = alignment$x, y = alignment$y, adj_x = alignment$x, adj_y = alignment$y,
                          pixel_x = alignment$pixel_x, pixel_y = alignment$pixel_y, barcode = alignment$barcode,
                          sample = paste0(i), stringsAsFactors = FALSE)
  rownames(alignment) <- paste0(alignment$x, "x", alignment$y, "_", i)
  return(alignment)
}))

meta.data.v13tov16 <- do.call(rbind, lapply(seq_along(spotfiles[5:8]), function(i) {
  alignment <- read.table(file = spotfiles[i + 4], header = FALSE, sep = ",", stringsAsFactors = FALSE)
  alignment <- setNames(alignment, nm = c("barcode", "selection", "y", "x", "pixel_y", "pixel_x"))
  sf <- jsonlite::read_json(path = json[i + 4])$tissue_hires_scalef*resize
  alignment$pixel_x <- alignment$pixel_x*sf
  alignment$pixel_y <- alignment$pixel_y*sf
  alignment <- subset(alignment, selection == 1)
  alignment$barcode <- paste0(alignment$barcode, "_", i) # Add unique section label
  alignment <- data.frame(x = alignment$x, y = alignment$y, adj_x = alignment$x, adj_y = alignment$y,
                          pixel_x = alignment$pixel_x, pixel_y = alignment$pixel_y, barcode = alignment$barcode,
                          sample = paste0(i), stringsAsFactors = FALSE)
  rownames(alignment) <- paste0(alignment$x, "x", alignment$y, "_", i)
  return(alignment)
}))

# Create Staffli object for v9-v12
st.object.v9tov12 <- CreateStaffliObject(imgs = he.images[1:4], meta.data = meta.data.v9tov12, 
                                         xdim = 400, platforms = rep("Visium", 4))
st.object.v9tov12
st.object.v13tov16 <- CreateStaffliObject(imgs = he.images[5:8], meta.data = meta.data.v13tov16, 
                                         xdim = 400, platforms = rep("Visium", 4))
st.object.v13tov16

```

If we apply the plot function to our Staffli object we will simply plot the spot coordinates

```{r plot_Staffli_new, fig.height=12, fig.width=12}

plot(st.object.v9tov12)
plot(st.object.v13tov16)

```

We can now load the Neun images and visualize the spots on top of them. The images are already quite well aligned, but there are some small offsets that we can correct for. Looking at the shape of the section I think a rigid alignment should suffice.

```{r load_images, fig.width=12, fig.height=12}

# Load images for v9 to v12
st.object.v9tov12 <- LoadImages(st.object.v9tov12, time.resolve = FALSE, verbose = TRUE)
plot(st.object.v9tov12, col = "red")

# Load images for v13 to v16
st.object.v13tov16 <- LoadImages(st.object.v13tov16, time.resolve = FALSE, verbose = TRUE)
plot(st.object.v13tov16, col = "red")

```

Before we can run the image alignment method, we need to mask the images, meaning that we need to remove the background around the tissue. We have a predefined option using the `MaskImages` function, but because these images are not HE stained the masking will fail. Instead we need to define a custom masking function that is specifically defined for this type of image.

First, we'll define a function to run the [SLIC algorithm](https://jayrambhia.com/blog/superpixels-slic) which can be a pretty neat tool to use in image segmentation and I found it to be particularly useful for masking. What the algorithm does is to clump together neighboring pixels of similary color intensity to create super pixels. These superpixels blur out small details, but can be very good at capturing the structure of larger shapes.

Below is an example of how the SLIC algorithm can be used to clump together pixels into super pixels.

```{r masking}

# Define slic function
slic <- function (im, nS, compactness = 1) {
  if (imager::spectrum(im) == 3) im <- imager::sRGBtoLab(im)
  sc.spat <- (dim(im)[1:2]*.28) %>% max
  sc.col <- imager::imsplit(im, "c") %>% purrr::map_dbl(sd) %>% max
  rat <- (sc.spat/sc.col)/(compactness*10)
  X <- as.data.frame(im*rat, wide = "c") %>% as.matrix
  ind <- round(seq(1, imager::nPix(im)/imager::spectrum(im), l = nS))
  km <- suppressWarnings({kmeans(X, X[ind, ])})
  sp <- purrr::map(1:imager::spectrum(im), ~ km$centers[km$cluster, 2+.]) %>% do.call(c, .) %>% imager::as.cimg(dim = dim(im))
  sp <- sp/rat
  if (imager::spectrum(im) == 3) {
    sp <- imager::LabtosRGB(sp)
  }
  return(sp)
}


# Run SLIC algorithm on an example image
im <- imager::load.image("https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Aster_Tataricus.JPG/1024px-Aster_Tataricus.JPG")
out <- slic(im, 600)
par(mfrow = c(1, 2), mar = c(0,0,0,0))
plot(im, axes = FALSE)
(out*abs(imager::imlap(out) == 0)) %>% plot(axes = FALSE)

```

## Mask images
***

Now we can define the custom masking function that takes an image of class "cimg" as input and returns a segmented image of class "pxset". Then we apply the custom masking function to our raw images using the `MaskImages` function.

### Mask images for v9-v12

```{r masking, fig.width=12, fig.height=12}

# Apply masking function to 
st.object.v9tov12 <- MaskImages(st.object.v9tov12, verbose = TRUE)
plot(st.object.v9tov12, col="#00000000", type = "raw")
plot(st.object.v9tov12, col="#00000000")

```

### Mask images for v13-v16

```{r masking, fig.width=12, fig.height=12}

# Define mask function
msk_fkn <- function (im) {
  im[im < mean(EBImage::otsu(im)*0.9)] <- 0
  im <- imager::medianblur(im, n = 14)
  out <- slic(im, nS = 600, compactness = 1)
  d <- imager::sRGBtoLab(out) %>% as.data.frame(wide = "c") %>%
        dplyr::select(-x, -y)
  km <- kmeans(d, 2)
  seg <- imager::as.cimg(km$cluster - 1, dim = c(dim(im)[1:2], 1, 1)) %>% imager::threshold()
}

# Apply masking function to 
st.object.v13tov16 <- MaskImages(st.object.v13tov16, custom.msk.fkn = msk_fkn, verbose = TRUE)
plot(st.object.v13tov16, col="#00000000", type = "raw")
plot(st.object.v13tov16, col="#00000000")

```

### Merge st.objects (optional)

Now we can combine these two objects into one st.object. This is a bit overcomplicated when working with a Staffli object, but it's relatively straightforward to run in STUtility on a Seurat object.

```{r merge_st_objects}

imgs <- setNames(c(st.object.v9tov12@imgs, st.object.v13tov16@imgs), nm = paste0(1:8))
rasterlists <- list()
rasterlists[["raw"]] <- setNames(c(st.object.v9tov12@rasterlists$raw, st.object.v13tov16@rasterlists$raw), nm = paste0(1:8))
rasterlists[["masked"]] <- setNames(c(st.object.v9tov12@rasterlists$masked, st.object.v13tov16@rasterlists$masked), nm = paste0(1:8))
rasterlists[["masked.masks"]] <- setNames(c(st.object.v9tov12@rasterlists$masked.masks, st.object.v13tov16@rasterlists$masked.masks), nm = paste0(1:8))
m2 <- st.object.v13tov16@meta.data
m2$sample <- paste0(as.integer(m2$sample) + 4)
m2$barcode <- paste0(gsub(pattern = "_[1-9]", replacement = "", x = m2$barcode), "_", m2$sample)
rownames(m2) <- paste0(gsub(pattern = "_[1-9]", replacement = "", x = rownames(m2)), "_", m2$sample)
st.meta.data <- rbind(st.object.v9tov12@meta.data[, 1:8], m2)
limits <- setNames(c(st.object.v9tov12@limits, st.object.v13tov16@limits), nm = paste0(1:8))
dims <- setNames(c(st.object.v9tov12@dims, st.object.v13tov16@dims), nm = paste0(1:8))
pixels.per.um <- setNames(c(st.object.v9tov12@pixels.per.um, st.object.v13tov16@pixels.per.um), nm = paste0(1:8))

st.object <- st.object.v9tov12
st.object@imgs <- imgs
st.object@rasterlists <- rasterlists
st.object@meta.data <- st.meta.data
st.object@limits <- limits
st.object@dims <- dims
st.object@platforms <- rep("Visium", 8)
st.object@samplenames <- paste0(1:8)
st.object@pixels.per.um <- pixels.per.um

plot(st.object, col = "red", cex = 0.2)

```

## Align images
***

Now that we have generated pretty decent masks for each tissue section, we can apply the alignment algorithm to find a transformation function. We will use section 1 as target for the alignment.

```{r alignment, fig.width=12, fig.height=12}

st.object.v9tov12 <- AlignImages(st.object.v9tov12, reference.index = 1)
plot(st.object.v9tov12, col = "#00000000")

st.object.v13tov16 <- ManualAlignImages(st.object.v13tov16, reference.index = 1)
st.object.v13tov16.rotated <- st.object.v13tov16
st.object.v13tov16.rotated@meta.data[, c("pixel_x", "pixel_y")] <- st.object.v13tov16.rotated@meta.data[, c("warped_x", "warped_y")]
st.object.v13tov16.rotated@rasterlists$masked <- st.object.v13tov16.rotated@rasterlists$processed
st.object.v13tov16.rotated@rasterlists$masked.masks <- st.object.v13tov16.rotated@rasterlists$processed.masks
st.object.v13tov16.rotated <- WarpImages(st.object.v13tov16.rotated, transforms = list("1" = list("angle" = 90), "2" = list("angle" = 90), "3" = list("angle" = 90), "4" = list("angle" = 90)))
plot(st.object.v13tov16.rotated, col = "#00000000")

saveRDS(st.object.v13tov16.rotated, file = "R_objects/st.object.v13tov16.rotated")
saveRDS(st.object.v9tov12, file = "R_objects/st.object.st.object.v9tov12")

```

## Warped coordinates
***

```{r plot_warped_coords, fig.height=6, fig.width=12}

p1 <- ggplot(st.object.v9tov12@meta.data, aes(warped_x, 2e3 - warped_y, color = sample)) +
  geom_point(size = 0.5) +
  theme_void() +
  ggtitle("Aligned coordinates v9 - v12") +
  scale_color_manual(values = c("#4477AA", "#117733", "#DDCC77", "#CC6677"))
p2 <- ggplot(st.object.v9tov12@meta.data, aes(warped_x, 2e3 - warped_y, color = sample)) +
  geom_point(size = 0.7) +
  theme_void() +
  facet_wrap(~sample) +
  scale_color_manual(values = c("#4477AA", "#117733", "#DDCC77", "#CC6677"))
cowplot::plot_grid(p1, p2)

p1 <- ggplot(st.object.v13tov16.rotated@meta.data, aes(warped_x, 2e3 - warped_y, color = sample)) +
  geom_point(size = 0.5) +
  theme_void() +
  ggtitle("Aligned coordinates v13 - v16") +
  scale_color_manual(values = c("#4477AA", "#117733", "#DDCC77", "#CC6677"))
p2 <- ggplot(st.object.v9tov12@meta.data, aes(warped_x, 2e3 - warped_y, color = sample)) +
  geom_point(size = 0.7) +
  theme_void() +
  facet_wrap(~sample) +
  scale_color_manual(values = c("#4477AA", "#117733", "#DDCC77", "#CC6677"))
cowplot::plot_grid(p1, p2)

```


## Apply transformation to segmented output
***

The next step will be to apply the transformation that we have just learned on the segmented nuclei. The `generate.map.affine` will be used to convert the transformation matrix into a function that takes a set of x and y coordinates. The `WarpCoords` function will then be usen to apply these function to the segmented nuclei x/y coordinates stored in our data.frames.

```{r transform_seg, fig.height=6, fig.width=6}

# Define map fkn
generate.map.affine <- function (
  tr, 
  forward = FALSE
) {
  if (forward) {
    map.affine <- function (x, y) {
      p <- cbind(x, y)
      xy <- t(solve(tr)%*%t(cbind(p, 1)))
      list(x = xy[, 1], y = xy[, 2])
    }
  } else {
    map.affine <- function (x, y) {
      p <- cbind(x, y)
      xy <- t(tr%*%t(cbind(p, 1)))
      list(x = xy[, 1], y = xy[, 2])
    }
  }
  return(map.affine)
}

# Define warp coordinates function
WarpCoords <- function (
  st.object, df
) {
  df <- df[, 1:4]
  df <- cbind(df, data.frame(warped_x = NA, warped_y = NA))
  for (i in 1:4) {
    dims.raw <- st.object@dims[[i]][, c("width", "height")] %>% as.numeric()
    dims.scaled <- scaled.imdims(st.object)[[i]]
    sf.xy <- dims.raw[2]/dims.scaled[1]
    
    tr <- st.object@transformations[[i]]
    map.affine.forward <- generate.map.affine(tr, forward = TRUE)
    df_subset <- subset(df, sample == paste0(i))
    df_subset[, c("x", "y")] <- df_subset[, c("x", "y")]/sf.xy
    warped_xy <- do.call(cbind, map.affine.forward(x = df_subset$x, y = df_subset$y))
    warped_xy <- warped_xy*sf.xy
    df[df$sample == i, c("warped_x", "warped_y")] <- warped_xy
  }
  return(df)
}

# Apply warp functions
dfs <- list(neurons = df.neurons, oligo = df.oligo, olig_neurons = df.oligo_neurons, unknown = df.unknown)
dfs <- lapply(dfs, function(df) {
  df <- WarpCoords(st.object.v13tov16, df)
})

```

Now we can create a set of pixel coordinates for the spots (set1) and a set of pixel coordinates for the nuclei (set2) in the same coordinate system. To set the z axis correctly I have multiplied the sample number (1-4) by the width of a tissue section in pixels (pixels.per.um*10)

```{r plot_seg_vs_aligned, fig.height=12, fig.width=12}

set1 = st.object.v13tov16@meta.data[, c("warped_x", "warped_y", "sample")]

set.list <- lapply(seq_along(dfs), function(i) {
  df <- dfs[[i]]
  set2 = df[, c("warped_x", "warped_y", "sample")]
})

par(mfrow = c(2, 2), mar = c(0, 0, 0, 0))
for(i in 1:4) {
  d <- dim(segmented.egfp.list[[i]][[1]])[2]
  plot(subset(set1, sample == i)[, 1:2], xlim = c(0, d), ylim = c(0, d), axes = F)
  points(subset(set.list[[1]], sample == i)[, 1:2], col = "red", cex = 0.2)
}

```


## Distance estimate
***

Now that we have the spot coordinates and the nuclei coordinates aligned and defined in the same coordinate system, we should be able to calculate pairwise distances between the two sets. Now, the distance will be defined as the 3D euclidean distance; d = sqrt((x2 - x1)^2 + (y2 - y1)^2 + (z2 - z1)^2)

The mindists object is a list with one distance matrix for each one of the data.frames in the dfs list (neurons, oligondendrocytes, olig_neun and uknown). These matrices will have as many rows as there are spots and as many columns as there are segmented cells in the data.frame object.

<br>
```{r distance}

pixels.per.um <- image.size.pixel/image.size.micron
set1 <- set1[, 1:2]
set.list <- lapply(set.list, function(set) {set[, 1:2]})

# Calculate pairwise distances
mindists <- lapply(set.list, function(set2) {
  mindist <- apply(set1, 1, function(x) {
    sqrt(colSums((t(set2) - x)^2))
  })
})

# spot radius in microns
sp.rad <- 27.5

# cell radius in microns
cell.rad <- 25

# Set threshold
thr <- pixels.per.um*sp.rad + pixels.per.um*cell.rad

# plot
hist(mindists[[1]], breaks = 100)
abline(v = thr, lty = "longdash", col = "red")

```

## Distance treshold
***

Now that we have set a threshold we can apply the threshold to select spots in proximity with nuclei and put the positions of both spots and neighboring nuclei into the dame data.frame.

```{r threshold_cells}
# Set all distances < thr to 0
# mindists[mindists > thr] <- NA
res.list <- lapply(seq_along(mindists), function(i) {
  df <- dfs[[i]]
  mindist <- mindists[[i]]
  ctype <- as.character(df$celltype)
  spts <- as.character(st.object@meta.data$barcode)
  res <- do.call(rbind, lapply(1:ncol(mindist), function(i) {
    x <- mindist[, i]
    inds = which(x <= thr)
    if (length(inds) > 0) {
      return(data.frame(celltype = ctype[inds], pixel_x_nuclei = df$warped_x[inds], 
                        pixel_y_nuclei = df$warped_y[inds], dist = x[inds], barcode = spts[i], 
                        x_spot = st.object.v13tov16@meta.data$warped_x[i], y_spot = st.object.v13tov16@meta.data$pixel_y[i], 
                        sample = df$sample[inds], stringsAsFactors = F))
    } else {
      return(NULL)
    }
  }))
})
all.cells <- do.call(rbind, res.list)

```

With this data.frame we can for example summarize the number of neighboring cells for each spot. 4 barcodes have been duplicated here, probably due to the fact that they have been assigned both an "unknown" label and an "oligo_neurons" label. We can just subset the data.frame to exclude these if we want to.

```{r get_cells_per_spots}

# Alt.1 : count all neighboring cells
summarized.cells <- all.cells %>% 
  group_by(barcode, celltype) %>% # Group data.frame by celltype and barcode
  summarize(celltype_f = n()) %>% # summarize for each celltype/barcode group the number of detected cells
  group_by(barcode) %>% # regroup data.frame by barcode only
  arrange(-celltype_f) %>% # Arrange each group by distances, from shortest to longest
  reshape2::dcast(formula = barcode ~ celltype, value.var = "celltype_f") # recast results into a wide format to keep 1 column per celltype

# Alt.2 : keep only closest neighbor
summarized.cells.keep.one <- all.cells %>% 
  group_by(barcode) %>% # group data.frame by barcode only
  top_n(n = 1, wt = -dist) # select cell with shortest distance for each barcode

cat("duplicated spots: ",  duplicated(summarized.cells.keep.one$barcode) %>% sum())
subset(summarized.cells.keep.one, barcode %in% summarized.cells.keep.one$barcode[duplicated(summarized.cells.keep.one$barcode)])


```


```{r 3D}

library(plotly)
plot_ly(subset(all.cells, !celltype %in% "unknown"), x = ~pixel_x_nuclei, y = ~pixel_y_nuclei, z = ~sample, color = ~celltype, size = 0.2)

```

```{r save_objects}

saveRDS(segmented.list, file = "R_objects/segmented.list")
saveRDS(segmented.egfp.list, file = "R_objects/segmented.egfp.list")

```


## Plot clones
***

```{r plot_clones}

# Load st.object for v9-v12
st.object.v9tov12 <- readRDS(file = "R_objects/st.object.st.object.v9tov12")
ids <- c("V9", "V10", "V11", "V12")
rownames(st.object.v9tov12@meta.data) <- paste0(ids[st.object.v9tov12@meta.data$sample %>% as.numeric()], "_", 
                                                         gsub(pattern = "_[1-4]$", replacement = "", x = st.object.v9tov12@meta.data$barcode))
# Load st.object for v13-v16
st.object.v13tov16.rotated <- readRDS(file = "R_objects/st.object.v13tov16.rotated")
ids <- c("V13", "V14", "V15", "V16")
rownames(st.object.v13tov16.rotated@meta.data) <- paste0(ids[st.object.v13tov16.rotated@meta.data$sample %>% as.numeric()], "_", 
                                                         gsub(pattern = "_[1-4]$", replacement = "", x = st.object.v13tov16.rotated@meta.data$barcode))

# Load Seurat object
load("data/merged.Rds")
brain.merge

# Export aligned HE image reference (section 1 from st.object.v9tov12.rotated)
library(magick)
lims <- st.object.v9tov12@dims[[1]][2:3] %>% as.numeric()
imr <- image_read(st.object.v9tov12@rasterlists$processed$`1`) %>% 
  image_scale(paste0(lims[1])) %>% 
  as.raster()
jpeg(filename = "results/reference_images/HE_aligned.jpeg", width = lims[1], height = lims[2])
par(mar = c(0, 0, 0, 0))
plot(imr)
dev.off()

# Export aligned Dapi image reference (section 1 st.object.v13tov16)
lims <- st.object.v13tov16.rotated@dims[[1]][2:3] %>% as.numeric()
imr <- image_read(st.object.v13tov16.rotated@rasterlists$processed$`1`) %>% 
  image_scale(paste0(lims[1])) %>% 
  as.raster()
jpeg(filename = "results/reference_images/Dapi_aligned.jpeg", width = lims[1], height = lims[2])
par(mar = c(0, 0, 0, 0))
plot(imr)
dev.off()

```


```{r plot_clone_fkn, fig.width=7, fig.height=6}

PlotFeatures <- function (
  object, 
  st.object, 
  atlas.img,
  feature = "cloneID",
  selected.clones = "0",
  pt.size = 2,
  pt.alpha = 1
) {
  if (!all(c("warped_x", "warped_y") %in% colnames(st.object@meta.data))) stop("Warped coordinates are missing in st.object")
  gg <- cbind(st.object@meta.data[, c("warped_x", "warped_y", "sample")])
  if (!feature %in% colnames(object@meta.data)) stop(paste0("feature ", feature, " is missing in Seurat object"))
  if (!class(object@meta.data[, feature]) %in% c("character", "factor")) stop(paste0("invalid class '", class(object@meta.data[, feature]), "' of selected feature"))
  gg[, feature] <- object@meta.data[rownames(gg), feature]
  imdims <- st.object@dims[[1]][2:3] %>% as.numeric()
  gg <- gg[gg[, feature] %in% selected.clones, ]
  
  im <- image_read(atlas.img) %>% image_scale(paste0(imdims[1], "x", imdims[2])) %>% as.raster()
  g <- grid::rasterGrob(im, width = unit(1, "npc"), height = unit(1, "npc"), interpolate = TRUE)
  ggplot() +
    annotation_custom(g, -Inf, Inf, -Inf, Inf) +
    geom_point(data = gg, aes_string("warped_x", "imdims[2] - warped_y", fill = feature), shape = 21, size = pt.size, alpha = pt.alpha) +
    theme_void() +
    scale_x_continuous(limits = c(0, imdims[1]), expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, imdims[2]), expand = c(0, 0))
}

# Plot all clones
PlotFeatures(object = brain.merge, st.object = st.object.v9tov12, selected.clones = unique(brain.merge$cloneID), atlas.img = "~/Michael_Ratz/cell_segmentation/data/atlas_reference-01.png", pt.alpha = 0.3)

# Plot selected clone
PlotFeatures(object = brain.merge, st.object = st.object.v9tov12, selected.clones = "5",
             atlas.img = "~/Michael_Ratz/cell_segmentation/results/reference_images/atlas_reference-01.png")

```

## Non-negative Matrix Factorization (NNMF)
***

```{r nmf}

brain.merge <- RunNMF(brain.merge, features = rownames(brain.merge@assays$SCT@scale.data), nfactors = 40)

```

### Plot NNMF factors
***

These factors are pretty useful for data exploration because thay are much easier to interpret than other dimensionality reduction vectors. In comparison with a PCA for example, the NNMF factors are always positive which makes them easier to interpret. I have also added the top 20 most contributing genes for each factor in a barplot to the right. I have only plotted the first factor, and the other ones I have exported as jpegs instead. 

```{r plot_nmfs, fig.width=20, fig.height=5}

p1 <- SpatialFeaturePlot(brain.merge, combine = FALSE, features = paste0("factor_", 1))
p2 <- FactorGeneLoadingPlot(brain.merge, factor = 1)
cowplot::plot_grid(cowplot::plot_grid(plotlist = p1, ncol = 4), p2, ncol = 2, rel_widths = c(4, 1)) %>% print()

for (i in 1:40) {
  jpeg(filename = paste0("data/NMF_plots/factor_", i, ".jpg"), width = 1600, height = 400)
  p1 <- SpatialFeaturePlot(brain.merge, combine = FALSE, features = paste0("factor_", i))
  p2 <- FactorGeneLoadingPlot(brain.merge, factor = i)
  cowplot::plot_grid(cowplot::plot_grid(plotlist = p1, ncol = 4), p2, ncol = 2, rel_widths = c(4, 1)) %>% print()
  dev.off()
}

```

### UMAP on NNMF vectors
***

The clusters are probably very similary to the ones obtained using PCA, but I think the UMAP looks pretty neat in comparison

```{r umap_nmf, fig.width=8, fig.height=7}

brain.merge <- RunUMAP(brain.merge, dims = 1:40, reduction = "NMF", reduction.key = "UMAPNMF_", reduction.name = "umap.nmf")
brain.merge <- RunUMAP(brain.merge, dims = 1:40, reduction = "NMF", n.components = 3, reduction.key = "UMAPNMF3D_", reduction.name = "umap.nmf.3d")
brain.merge <- FindNeighbors(brain.merge, dims = 1:40, reduction = "NMF")
brain.merge <- FindClusters(brain.merge)

DimPlot(brain.merge, reduction = "umap.nmf")

```

### CMYK color coding of spots
***

```{r UMAP_CMYK, fig.height=12, fig.width=12}

cmyk <- function(C,M,Y,K = 0) {
  
  C <- C / 100.0
  M <- M / 100.0
  Y <- Y / 100.0
  K <- K / 100.0
  
  n.c <- (C * (1-K) + K)
  n.m <- (M * (1-K) + K)  
  n.y <- (Y * (1-K) + K)
  
  r.col <- ceiling(255 * (1-n.c))
  g.col <- ceiling(255 * (1-n.m))
  b.col <- ceiling(255 * (1-n.y))
  
  rgb(red = r.col, green = g.col, blue = b.col, maxColorValue = 255)
}


CMYKPlot <- function (
  object, 
  K = 0,
  sampleid = NULL,
  dims = 1:3,
  reduction = "umap.nmf.3d",
  pt.size = 1
) {
  um <- object[[reduction]]@cell.embeddings
  if (length(dims) !=3) stop("3 dimensions must be selected")
  signs <- sign(dims)
  um <- um[, abs(dims)]
  um <- t(t(um)*signs)
  if (ncol(um) != 3) stop("Reduction must be 3 dimensions")
  um <- apply(um, 2, scales::rescale, c(0, 100))
  cols <- apply(um, 1, function(x) {
    cmyk(C = x[1], M = x[2], Y = x[3], K = K)
  })
  gg <- do.call(rbind, lapply(seq_along(object@images), function(i) {
    x <- object@images[[i]]
    d <- x@coordinates
    d$sample <- paste0(i)
    return(d)
  }))
  gg$colors <- cols
  if (!is.null(sampleid)) {
    gg <- subset(gg, sample == paste0(sampleid))
  }
  ggplot(gg, aes(78 - col, row)) +
    geom_point(color = gg$colors, size = pt.size) +
    facet_wrap(~sample) +
    theme_void()
}

CMYKPlot(brain.merge, reduction = "umap.nmf.3d", pt.size = 2)

```

```{r plot_clusters, fig.height=4, fig.width=16}

cluster.cols <- c('#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000')

SpatialPlot(brain.merge, cols = cluster.cols)

```


### DE analysis of clusters
***

```{r de_analysis, fig.width=8, fig.height=20}

de.markers <- FindAllMarkers(brain.merge)
top5 <- de.markers %>% group_by(cluster) %>% top_n(n = 5, wt = avg_logFC)

DotPlot(brain.merge, features = unique(top5$gene), cols = "RdBu") + coord_flip()

```
